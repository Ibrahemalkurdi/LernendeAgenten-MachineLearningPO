{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/understanding-rnn-and-lstm-f7cdf6dfc14e\n",
    "\n",
    "LSTM und RNNs gut erklärt: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeines\n",
    "\n",
    "Allgemeines Problem von sehr tiefen NNs ist, dass es irgendwann untraierbar wird, da ganz am Ende bei der Backpropagation, kaum noch Lerneffekte bei den vorderen Layern auftreten.\n",
    "\n",
    "Bei einem simplen RNN geht der Input nach ein paar Schritten verloren, sodass man sich nicht mehr sicher sein kann, was der ursprüngliche Input war. (siehe Problem des verschwindenden Gradienten).\n",
    "Das SimpleRNN sollte aber eigentlich zu jedem Zeitpunkt t auf Informationen über vor vielen Zeitschritten erfolgte Eingaben zugreifen können.\n",
    "\n",
    "Beim RNN mit LSTM (Long-Short-Term Memory) wird der Input parallel unverändert mitgeführt, sodass der ursprüngliche Input an jeder Stelle des Netzes erreichbar ist\n",
    "\n",
    "\n",
    "### LSTM\n",
    "\n",
    "![LSTM Grafik](https://miro.medium.com/max/1044/1*MwU5yk8f9d6IcLybvGgNxA.jpeg)\n",
    "\n",
    "##### Forget Gate\n",
    "\n",
    "Verbinde vorherigen Status und aktuellen Input in einer Matriz. Multipliziere diesse mit der Gewichtung, addiere den Bias.\n",
    "Dann wende auf die entstehende Matriz die Sigmoid-Funktion an.\n",
    "\n",
    "![](https://miro.medium.com/max/770/1*bQnecA5sy_eepNkL8I-95A.png)\n",
    "\n",
    "##### Input Gate\n",
    "\n",
    "Wende auf den Output vom Forget Gate die tanh-Funktion an, um den Werten ihre Gewichtung (Wichtigkeitslevel von -1 bis 1) zuzuweisen\n",
    "\n",
    "![](https://miro.medium.com/max/869/1*k1lxwjsxxn8O4BEiVlQNdg.png)\n",
    "\n",
    "##### Output Gate\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1170/1*s8532P11PgGi2sZqikZ2kA.png)\n",
    "\n",
    "## GRU (Gate recurrent units)\n",
    "\n",
    "Im Gegensatz zum LSTM gibt es bei GRU nur zwei Gates:\n",
    "\n",
    "##### Reset Gate\n",
    "\n",
    "\n",
    "\n",
    "##### Update Gate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
